---
title: "GetCWMSdataWill"
author: "Norm Buccola"
date: "2025-10-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Analysis of Operations and WQ from CWMS


```{r SetupParams}
# Get operations, temperature, TDG data for analysis
rm(list = ls())
# First time this is run, need to install the following packages
#install.packages(c('reshape2','foreach','lubridate','ggplot2','plyr','RColorBrewer','scales','data.table','magrittr',
# 'tidyverse','plotly','akima','plotly'), repos='http://cran.us.r-project.org')
#library(devtools)
#install.packages('cwmsr', source = TRUE, lib.loc = "C:/Repositories/cwmsr") #, repos=NULL
#install_github("nbuccola/cwmsr")
#install.packages('cwmsr')
library(cwmsr)
library(foreach)
library(dplyr)
library(ggplot2)
library(tidyr)
#install.packages('tidyverse')
library(tidyverse)
library(purrr)
library(readxl)
#library(w2r)

######################
# BEGIN USER INPUT #
######################
# Setup input variables

# Setup paths
LocalWd <- 'C:/Repositories/cwmsr'
WriteDir <- 'C:/Users/g2echnb9/OneDrive - US Army Corps of Engineers/Documents/WOOT/Analysis'
CDApath <- 'https://wm.nww.ds.usace.army.mil:8243/nwdp-data/'

# Setup Begin and end dates
bdate <- strptime('2000-01-01',"%Y-%m-%d",tz = 'PST8PDT')
edate <- strptime('2025-12-31',"%Y-%m-%d",tz = 'PST8PDT')
#
yrs <- gsub(', ','',toString(unique(c(format(bdate,'%Y'),format(edate,'%Y')))))
# If only want to get more current data for all paths
#edate <- "Update"    


# Setup which sites to retrieve
Projects = 'All' #c('GPR','FOS') #'FAL' #  #c('CGR','FAL')

# Setup path to JSON config file for all project data paths
cnfg = jsonlite::fromJSON(file.path(LocalWd,"inst","WillCWMSTempTDGConfig.json"))

# Declare if only specific CWMS paths are to be read, declare them here.
# SpecificCWMSpaths <- 'FBWSELVRule'
# SpecificCWMSpaths <- 'GDACS_Gates'
#SpecificCWMSpaths <- c("TDGdwnStrmPath")

# Setup path to previous Rdata files. 
# If none, declare NA and a new directory will be created
PreviousRdataDir = NA
PreviousRdataDir = file.path(WriteDir,'Wil_All_Ops20002025')

######################
# END USER INPUT #
######################

# Load Outlet elevations: variable qgtConfig
source(file.path(WriteDir,'data','QGTelvs_2026-01-06.r'))
qgtConfig$SubBasins <- data.frame(SubBasin = unlist(qgtConfig$SubBasins[1,]),
                                  Proj = colnames(qgtConfig$SubBasins)) |>
  mutate(SubBasin = factor(SubBasin,levels = c('NSant','SSant','SFMck','MFWil'),ordered=T))
# Load OR DEQ WQ standards: variable wqCrit
source(file.path(WriteDir,'data','ORDEQ_wqCrit.r'))

cnfg = cnfg[['projects']]
SiteAcrnms <- sapply(cnfg,function(x){unlist(x[grep('Site|Acrnm',names(x))])})
names(cnfg)

if(Projects[1] ==  'All'){
  whichProj <- 1:length(cnfg)
}else{
  whichProj <- which(names(cnfg) %in% Projects)
}

if(is.na(PreviousRdataDir)){
  # Create Folder For New Data
  RdataDir <- file.path(WriteDir,paste0('Wil_',gsub(',| ','',toString(Projects)),'_Ops',yrs))
  dir.create(RdataDir)
}else{
  RdataDir <- PreviousRdataDir
  if(!dir.exists(RdataDir)){
    dir.create(RdataDir)
  }
}
fls <- list.files(RdataDir,pattern = '.Rdata')
RawFls <- fls[grepl('Raw',fls)]
CleanFls <- fls[grepl('Clean',fls)]
    

for(i in whichProj){
  #i = 1
  Proj <- cnfg[[i]][[grep('ProjAcrnm',names(cnfg[[i]]))]]
  if(!is.na(PreviousRdataDir)){
    OldRdataDirProj <- file.path(RdataDir,RawFls[grepl(paste0(Proj,'_'),RawFls)])
    cnfg[[i]][['OldRdataDirProj']] <- cnfg[[i]][['RdataDirProj']] <- OldRdataDirProj
    cnfg[[i]][['dataFileName']] <- rev(strsplit(OldRdataDirProj,'\\/')[[1]])[1]
    if(exists('SpecificCWMSpaths')){
      # Only get CWMS paths that are declared here
      cnfg[[i]][['cwms_paths']] <- 
        cnfg[[i]][['cwms_paths']][grepl(SpecificCWMSpaths,names(cnfg[[i]][['cwms_paths']]))]
      cnfg[[i]][['mergeNewPaths']] <- TRUE
    }else{
      cnfg[[i]][['mergeNewPaths']] <- FALSE
    }
  }else{
    cnfg[[i]][['dataFileName']] <- paste0(Proj,'_OpsRaw',yrs,'.Rdata')
    cnfg[[i]][['RdataDirProj']] <- file.path(RdataDir,dataFileName)
    cnfg[[i]][['mergeNewPaths']] <- FALSE
  }
  cnfg[[i]][['edate']] <- edate
}

```

## Get data for each project

```{r GetCWMSopsData, echo=FALSE}

for(i in whichProj){
  #i = 8 
  Proj <- cnfg[[i]][[grep('ProjAcrnm',names(cnfg[[i]]))]]
  source(file.path(LocalWd,'R','get_cwms_utilities.r'))
  GetCWMSdata(p = cnfg[[i]],bdate=bdate,edate = cnfg[[i]][['edate']],
              mergeNewPaths = cnfg[[i]][['mergeNewPaths']])
}

```

Create a regular time-series

```{r ConvertRawDataToHourly}

for(i in whichProj){
  #i=10
  Proj <- cnfg[[i]][[grep('ProjAcrnm',names(cnfg[[i]]))]]
  print(Proj)
  # Load project data
  load(file.path(RdataDir,cnfg[[i]][['dataFileName']]))
  
  # Interpolate to hourly data and remove missing columns
  source(file.path(LocalWd,'R','get_cwms_utilities.r'))
  InterpCols(RdataDirProj = cnfg[[i]][['RdataDirProj']])
}
  
```


```{r CleanAndProcessRawData}

tsites <- data.frame(BCL = 'BCLO',CGR = 'CGRO',FOS = 'SSFO',FAL = 'FALO',DEX = 'DEXO',HCR = 'HCRO')
tsites[1,] <- paste0(tsites[1,],'.Temp-Water')#,collapse='|')
TDGSites <- c('DET','BCLO','GPRO','SSFO','CGRO','HCRO','LPQO','DEXO') #'BCL','CGR',
appendProcessed <- T # If you want to use the calculated and processed data instead of re-processing (can take a while) prior to metric calcs 

for(i in whichProj){
  Proj <- cnfg[[i]][[grep('ProjAcrnm',names(cnfg[[i]]))]]
  print(Proj)
  # Load project data
  if(appendProcessed){
    load(file.path(RdataDir,gsub('Raw','Processed',cnfg[[i]][['dataFileName']])))
  }else{
    load(file.path(RdataDir,gsub('Raw','HrlyClean',cnfg[[i]][['dataFileName']])))
    # Calculate weighted average of inflow temperature
    if(any(grepl('QinPath',names(cnfg[[i]][['cwms_paths']]))) & !grepl('LOP',Proj)){
      source(file.path(LocalWd,'R','temp_calcs.r'))
      CalcTin(cwms_paths = cnfg[[i]][['cwms_paths']])
    }
    # Remove Outliers, Calculate Dailys, Monthly, Annual Summaries, Plot output
    source(file.path(LocalWd,'R','get_cwms_utilities.r'))
    calcDailyMonthlyAnn()
    # Calculate the 7dADM on temperature variables
    source(file.path(LocalWd,'R','temp_calcs.r'))
    calc7dadm(xld)
  }
  rm(xlmExc,xlmExcL)

  if(any(grepl(Proj,names(tsites))) |
     any(grepl(Proj,TDGSites))){
    # Calculate days of exceedance for Temperature variables
    # Check for temperature data and sites of interest
    source(file.path(LocalWd,'R','temp_calcs.r'))
    xlmExcL <- list(NA)
    xlmExcL[['Temp']] <- calcThreshMon(DataType = 'Temp-Water',TVals = c(16,18,20,'TTargPath'))
    xlmExcL[['TDG']] <- calcThreshMon(DataType = 'TDG',TVals = c(110,120))
    xlmExcL[['Elev-Temp']] <- calcThreshMon(DataType = c('Elev-Forebay','Spill'),TVals = 'WtempControl')
    #xlmElevExc <- calcThreshMon(DataType = 'Opening',TVals = 'GateOpen') # Check if monthly summaries will work
    #xlmFlowExc <- calcThreshMon(DataType = 'Flow',TVals = 'QTargPath') # Not implemented yet; only applies to SLM
    xlmExcL <- Filter(Negate(is.logical), xlmExcL)
    xlmExc <- purrr::reduce(xlmExcL,full_join)
  
    # Calculate Annual Exceedances
    xlaExc <- calcThreshAnn(xlmExc |> filter(!grepl('DysWTempCon',ExcType))) |>
      full_join(calcThreshAnn(xlmExc |> filter(grepl('DysWTempCon',ExcType)),months = 4:9))
    
    # Estimate Egg Emergence
    if(any(grepl(Proj,names(tsites)))){
      # Estimate Emergence for spring chinook (spawning in fall)
      source(file.path(LocalWd,'R','temp_calcs.r'))
      xlaChnkEggEmrg <- EstimateEmergence(xld,
                        spawnDay = c(244,263,274),
                        hatchValue = 1750
                        )
      if(any(grepl(Proj,c('BCL','FOS')))){
        # Estimate Emergence for winter steelhead (spawning in spring)
        # From 94-98 Winter Steelhead from Marion Forks Hatchery Program
        # Hatch = 510-540 ATU
        # Swim up/Emergence = 920-950 ATU
        # Start at 5/1, 5/15, 6/1
        xlaStlhdEggEmrg <-EstimateEmergence(xld, #[grepl(Proj,xld$name),],
                          spawnDay = c(121, 166, 182),
                          hatchValue = 935
                          )
        xlaEggEmrg <- xlaChnkEggEmrg |>
                      mutate(species = 'Spring Chinook') |>
          full_join(xlaStlhdEggEmrg |>
                      mutate(species = 'Winter Steelhead'))
      }else{
        xlaEggEmrg <- xlaChnkEggEmrg |>
                      mutate(species = 'Spring Chinook') 
      }
      xlaEggEmrg <- xlaEggEmrg |>
          mutate(name = unique(xld$name)[grepl(tsites[,names(tsites) %in% Proj],unique(xld$name)) &
                                           !grepl("Targ",unique(xld$name))])
      rm(xlaChnkEggEmrg,xlaStlhdEggEmrg) 
    }else{
      print(paste("Skipping Estimated Emergence;",Proj,"Not a compliance point for temperature"))
      xlaEggEmrg <- NULL
    }
  }else{
    xlmExc <- NULL
    xlaExc <- NULL
    xlaEggEmrg <- NULL
  }

  #Save New Processed Data as Rdata File
  save(Proj,OutletI,xw,xld,xldSum,xlm,xlmExc,xla,xlaExc,xlaEggEmrg,#cwms_paths,
       file = file.path(RdataDir,gsub('_OpsRaw','_OpsProcessed',cnfg[[i]][['dataFileName']])))
  
  rm(xw,xld,xldSum,xlm,xlmExc,xlmExcL,xla,xlaExc,xlaEggEmrg,Proj)
}

```


Get Operator Log Book data
Prior to next step, copy log books from:
1) DET-BCL:
\\nwd\nwp-ETDS\Engineering_Division\CENWP-EC-H\CENWP-EC-HR\RES_REG\WILLAMETTE\PROJECTS\Detroit\Log_Sheets
2) LOP:
3) FOS: 






```{r LoadGDACSgateOpenings}
# Load GDACs Data
GateDataList <- list(NA)
for(i in whichProj){
  Proj <- cnfg[[i]][[grep('ProjAcrnm',names(cnfg[[i]]))]]
  print(Proj)
  # Load project data
  load(file.path(RdataDir,gsub('Raw','HrlyClean',cnfg[[i]][['dataFileName']])))
  if(any(grepl('Opening|Gen',colnames(xw)))){
    GateDataList[[i]] <- xw |>
      dplyr::select('DateTime',contains('Open'),contains('Flow-Gen'),contains('Flow-Spill'),contains('Flow-Out')) |>
      filter(DateTime>as.POSIXct('2024-12-31'))
  }
  
}
GateDataList <- Filter(Negate(is.null), GateDataList)
Gts <- purrr::reduce(GateDataList,full_join) 
rm(GateDataList)
GtsCWMS <- Gts |>
  pivot_longer(-DateTime) |>
  mutate(name = gsub('.Inst|.0.0|.1Hour|.Ave|.CBT-REV|.Best|.MIXED-REV|.GDACS-RAW','',name),
         name = gsub('DT-E','DTE',gsub('DT-G','DTG',name)),
         name = gsub('ft-','ft',gsub('n-E','nE',gsub('.Code-Open','.Opening',name)))) |>
  separate_wider_delim(name,delim='-',names = c('name','gate')) |>
  mutate(data = 'CWMS',
         param = if_else(grepl('Flow',gate),'Flow',if_else(grepl('Open',gate),'Opn','NA')),
         gate = gsub('.Flow|.Open','',gate))
 


```


```{r LoadGateOpeningData}
NewDETBCLGateFile = 'DETBCL_logbookScraped2014-2025.Rdata'
gatePath = file.path(WriteDir,'GateOpenings','DETBCL')

RdataFls <- list.files(RdataDir,pattern = '.Rdata',full.names = T)
scrapeNewLogBooks <- F
source(file.path(LocalWd,'R','read_opslogbooks.r'))
if(scrapeNewLogBooks){
  getDETBCLScrapedOpsLogBooks(
    gatePath=gatePath,
    previousScrapeFile = NewDETBCLGateFile)
}

# Merge Logbook gate opening data with DET-BCL ops and TDG:
source(file.path(LocalWd,'R','read_opslogbooks.r'))
GtOpnWV <- MergeGateOpsWflowWQ(
  DETBCLGateOpsFileName = file.path(gatePath,NewDETBCLGateFile),
  LOPlogbookFileName = file.path(WriteDir,'GateOpenings','USACE_LOPHCRDEXCGR_ops_v01072026.RData'),
  GtsCWMS = GtsCWMS)

# Left off here!!! Waiting for GPR-FOS data from Jack. Go through each project and send flow data for each outlet to Will.

source(file.path(LocalWd,'R','read_opslogbooks.r'))
MakeProjFlowData4Will(SaveName = '2025GateOps')

```


```{r PlotMetrics}

DataList <- list(Exc = list(NA),
                 Stats = list(NA))

for(i in whichProj){
  Proj <- cnfg[[i]][[grep('ProjAcrnm',names(cnfg[[i]]))]]
  print(Proj)
  # Load project data
  load(file.path(RdataDir,gsub('Raw','Processed',cnfg[[i]][['dataFileName']])))
  if(!is.null(xlmExc)){
    DataList[['Exc']][[i]] <- 
      xlmExc |>
      full_join(xlaExc |> mutate(Month = 'Annual'),
                xlaEggEmrg, by = c('name','Year','Month','TValsNum','ExcType','PrcExc','Exc'))
  }
  DataList[['Stats']][[i]] <- 
    xlm |> mutate(Month = as.character(Month)) |>
    full_join(xla |> mutate(Month = 'Annual',
                            Year = as.numeric(as.character(Year)),
                            name = as.character(name))
              )
  if(exists('xlaEggEmrg')){
    DataList[['EggEmrg']][[i]] <- xlaEggEmrg
  }
  rm(xw,xld,xldSum,xlm,xlmExc,xla,xlaExc,xlaEggEmrg,Proj)
}
DataList[['Exc']] <- Filter(Negate(is.null), DataList[['Exc']])
DataList[['Stats']] <- Filter(Negate(is.null), DataList[['Stats']])
DataList[['EggEmrg']] <- Filter(Negate(is.null), DataList[['EggEmrg']])
OpsExc <- purrr::reduce(DataList[['Exc']],full_join) 
OpsStats <- purrr::reduce(DataList[['Stats']],full_join) 
OpsEggEmrg <- purrr::reduce(DataList[['EggEmrg']],full_join) 
rm(DataList)

# Example using a common colorblind-friendly palette
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73",  "#0072B2", "#D55E00", "#CC79A7") #"#F0E442",
clrs<- cbPalette[c(1:4,6)]
names(clrs) <- c(2021:2025)

sb <- levels(qgtConfig$SubBasins$SubBasin)
PlotDataList <- as.list(sb)
source(file.path(LocalWd,'R','AnnMetricPlotting.r'))
 # Left off line 286 with GPR/FOS

for(i in 1:nlevels(qgtConfig$SubBasins$SubBasin)){
  PlotDataList[[i]] <-  MultiYrQPlots(
    SubBasinSites = qgtConfig$SubBasins[grep(sb[i],qgtConfig$SubBasins$SubBasin),],
    SaveName = '2025Ops')
    
}
# Flow Metrics
OpsExc


# Iterate through Rdata files and merge into one large file (xw, xwd,xwdSum,xAnn variables)
oldDataFileName <- 'DET_HistoricOpsTemp2000-2025.Rdata'
newDataFileName <- paste0('_HistOpsWQ',format(bdate,'%Y'),'-',format(edate,'%Y'),'.Rdata')
if(!file.exists(file.path(RdataDir,newDataFileName))){
    merge_tibbles_from_rdata(oldDataFileName,newDataFileName)
  }
load(file.path(RdataDir,newDataFileName))


MakeMultiYrPlots()


```

```{r FishData}

for(i in iterateHere){
  
  # Read in AFF Fish count data
  AFF <- read_csv(file.path(LocalWd,'CougarFishTrap_AllData_ForNorm.csv')) %>%
    dplyr::select(`Date`,contains(c('Chinook','STS'))) |> #_unmarked _unmarked
    pivot_longer(cols=-Date) |>
    mutate(Date = as.Date(Date,format='%m/%d/%Y'),
           ChOrSt = if_else(grepl('Chinook',name),'Total_CH','Total_ST')) |>
    group_by(Date,ChOrSt) |>
    reframe(#Year = Year,
            Total = sum(value,na.rm=T)) |>
    pivot_wider(names_from = ChOrSt,values_from = Total) |>
    mutate(Year = as.factor(strftime(Date,'%Y'))) |>
    group_by(Year) |>
    reframe(Date = Date,
            Cum_CH = cumsum(Total_CH),
            Cum_ST = cumsum(Total_ST)) |>
    select(-Year) 
  
  # Read in RST Fish trap count data
  rstFls <- list.files(file.path(LocalWd,'CougarRST_EAS_2023-2025'))
  rm(X)
  for(i in 1:length(rstFls)){
    x <- read_xlsx(file.path(LocalWd,'CougarRST_EAS_2023-2025',rstFls[i]),sheet=1) |>
      janitor::clean_names() 
    x <- x |>
      select('week_of_the_project',"x_axis_labels2","trap",
             "weekly_catch",
             contains(c("cumulative",'elev_forebayft','spill_cfs','avg_gen')))|>
      mutate(Year = rev(strsplit(rstFls[i],' ')[[1]])[1],
             Year = as.numeric(gsub('.xlsx','',Year)))
    colnames(x) <- gsub('cumulative_catch','cumulative_count',colnames(x))
    if(i==1){
      X <- x
    }else{
      X <- rbind(X,x)
    }
  }
  RST <- X |>
    rename(Week = week_of_the_project,xlabs = x_axis_labels2,
           Catch = weekly_catch,CumCount = cumulative_count,
           ForeBayElev = avg_of_avg_of_cgr_elev_forebayft,
           Spill = wk_avg_spill_cfs,
           Gen= wk_avg_gen_cfs) |>
    # Convert week to date
    mutate(Date = as.Date(paste0(Year,'-',
                            sprintf("%02d",as.numeric(unlist(lapply(xlabs,function(x)strsplit(x,'_')[[1]][1])))),'-',
                            unlist(lapply(xlabs,function(x)strsplit(x,'_')[[1]][2]))),format='%Y-%d-%b')) |>
    filter(!is.na(Week),!is.na(trap)) |>
    pivot_wider(id_cols = c(Week,Date,Year),names_from = trap,values_from = c(Catch,CumCount)) |>
    arrange(Week)
  rm(x,X)
  str(RST)
  summary(RST)
  #print(RST[RST$Year==2025,],n=200)

  # Calc AFF upstream migrant counts and ops data metrics
  calcAFFAnnMetrics()

  # Calc RST downstream migrant counts and ops data metrics
  calcDSPassAnnMetrics()

  # Left off here
  
  #Re-save as Rdata File
  save(xw,xwd,xwdSum,xAnn,Proj,cwms_paths,
       file = file.path(LocalWd,dataFileName))
  
  rm(xw,xwd,xAnn,xwdSum,Proj,dataFileName)

  }
  
  # Iterate through Rdata files and merge into one large file (xw, xwd,xwdSum,xAnn variables)
  newDataFileName <- paste0('DETBCLGPRFOSHCRLOPDEX_HistOpsTempTDG',format(bdate,'%Y'),'-',format(edate,'%Y'),'.Rdata')
  if(!file.exists(file.path(file.path(LocalWd,HistoricPath,newDataFileName)))){
    merge_tibbles_from_rdata(newDataFileName)
  }
  load(file.path(file.path(LocalWd,HistoricPath,newDataFileName)))

  # Read in met files to merge with other WQ data (xw, xwd variables)
  ReadMergeMetData()
  
  newDataFileName <- paste0('DETBCLGPRFOSHCRLOPDEX_HistOpsTempTDGwDET-BCLops',format(bdate,'%Y'),'-',format(edate,'%Y'),'.Rdata')
  loadScrapedOpsLogBooks(newDataFileName)

}





```





```{r WriteDSSfile}
# Set which years for DSS file creation
extractYr <- 2016
# For now, write a csv file for 2016 data
# v1.01  = DETBCLGPRFOSHCRLOPDEX_HistOpsTempMetTDGwDET-BCLops
write.csv(XwMetOps |> 
            filter(DateTime >= as.POSIXct('2016-01-01') &
                     DateTime < as.POSIXct('2017-01-01')),
          file = file.path(LocalWd,'ResSim','data','DSSfiles','WillTempHourly2016_v1.01.csv'),
          quote = F,row.names = F)

write.csv(XwdMetOps |> 
            filter(Date >= as.Date('2016-01-01') &
                     Date < as.Date('2017-01-01')),
          file = file.path(LocalWd,'ResSim','data','DSSfiles','WillTempDaily2016_v1.01.csv'),
          quote = F,row.names = F)


remotes::install_github("mkoohafkan/dssrip2",build_vignettes = TRUE)
library(dssrip2)

# Left off here, not able to run this yet

dss_install_monolith()
dss_connect(monolith = TRUE)
# Subset the year of interest



```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
